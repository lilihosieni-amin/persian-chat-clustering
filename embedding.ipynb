{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olmjexNB3P5U",
        "outputId": "ad77ed98-b684-4eaa-e312-914c2fd04b8c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "شروع پردازش فایل /content/drive/MyDrive/Doukt/Goftino/NLP/colab/embedd/preproces.csv با اندازه چانک 1000 و 5 درخواست همزمان...\n",
            "پردازش چانک 1 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 1: 100%|██████████| 1000/1000 [01:13<00:00, 13.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 1 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 2 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 2: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 2 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 3 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 3: 100%|██████████| 1000/1000 [01:06<00:00, 15.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 3 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 4 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 4: 100%|██████████| 1000/1000 [01:09<00:00, 14.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 4 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 5 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 5: 100%|██████████| 1000/1000 [01:18<00:00, 12.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 5 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 6 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 6: 100%|██████████| 1000/1000 [01:13<00:00, 13.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 6 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 7 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 7: 100%|██████████| 1000/1000 [01:07<00:00, 14.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 7 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 8 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 8: 100%|██████████| 1000/1000 [01:13<00:00, 13.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 8 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 9 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 9: 100%|██████████| 1000/1000 [01:12<00:00, 13.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 9 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 10 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 10: 100%|██████████| 1000/1000 [01:22<00:00, 12.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 10 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 11 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 11: 100%|██████████| 1000/1000 [01:20<00:00, 12.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 11 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 12 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 12: 100%|██████████| 1000/1000 [01:13<00:00, 13.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 12 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 13 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 13: 100%|██████████| 1000/1000 [01:09<00:00, 14.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 13 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 14 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 14: 100%|██████████| 1000/1000 [01:16<00:00, 13.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 14 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 15 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 15: 100%|██████████| 1000/1000 [01:11<00:00, 14.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 15 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 16 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 16: 100%|██████████| 1000/1000 [01:10<00:00, 14.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 16 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 17 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 17: 100%|██████████| 1000/1000 [01:12<00:00, 13.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 17 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 18 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 18: 100%|██████████| 1000/1000 [01:09<00:00, 14.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 18 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 19 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 19: 100%|██████████| 1000/1000 [01:08<00:00, 14.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 19 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 20 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 20: 100%|██████████| 1000/1000 [01:05<00:00, 15.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 20 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 21 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 21: 100%|██████████| 1000/1000 [01:08<00:00, 14.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 21 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 22 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 22: 100%|██████████| 1000/1000 [01:13<00:00, 13.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 22 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 23 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 23: 100%|██████████| 1000/1000 [01:12<00:00, 13.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 23 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 24 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 24: 100%|██████████| 1000/1000 [01:12<00:00, 13.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 24 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 25 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 25: 100%|██████████| 1000/1000 [01:18<00:00, 12.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 25 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 26 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 26: 100%|██████████| 1000/1000 [01:07<00:00, 14.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 26 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 27 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 27: 100%|██████████| 1000/1000 [01:15<00:00, 13.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 27 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 28 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 28: 100%|██████████| 1000/1000 [01:27<00:00, 11.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 28 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 29 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 29: 100%|██████████| 1000/1000 [01:05<00:00, 15.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 29 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 30 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 30: 100%|██████████| 1000/1000 [01:13<00:00, 13.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 30 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 31 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 31: 100%|██████████| 1000/1000 [01:10<00:00, 14.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 31 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 32 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 32: 100%|██████████| 1000/1000 [01:04<00:00, 15.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 32 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 33 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 33: 100%|██████████| 1000/1000 [01:06<00:00, 15.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 33 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 34 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 34: 100%|██████████| 1000/1000 [01:52<00:00,  8.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 34 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 35 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 35: 100%|██████████| 1000/1000 [01:09<00:00, 14.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 35 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 36 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 36: 100%|██████████| 1000/1000 [01:08<00:00, 14.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 36 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 37 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 37: 100%|██████████| 1000/1000 [01:15<00:00, 13.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 37 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 38 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 38: 100%|██████████| 1000/1000 [01:12<00:00, 13.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 38 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 39 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 39: 100%|██████████| 1000/1000 [01:12<00:00, 13.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 39 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 40 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 40: 100%|██████████| 1000/1000 [01:18<00:00, 12.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 40 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 41 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 41: 100%|██████████| 1000/1000 [01:09<00:00, 14.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 41 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 42 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 42: 100%|██████████| 1000/1000 [01:12<00:00, 13.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 42 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 43 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 43: 100%|██████████| 1000/1000 [01:14<00:00, 13.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 43 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 44 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 44: 100%|██████████| 1000/1000 [01:11<00:00, 14.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 44 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 45 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 45: 100%|██████████| 1000/1000 [01:13<00:00, 13.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 45 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 46 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 46: 100%|██████████| 1000/1000 [01:13<00:00, 13.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 46 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 47 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 47: 100%|██████████| 1000/1000 [01:09<00:00, 14.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 47 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 48 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 48: 100%|██████████| 1000/1000 [01:11<00:00, 13.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 48 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 49 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 49: 100%|██████████| 1000/1000 [01:04<00:00, 15.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 49 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 50 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 50: 100%|██████████| 1000/1000 [01:05<00:00, 15.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 50 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 51 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 51: 100%|██████████| 1000/1000 [01:21<00:00, 12.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 51 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 52 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 52: 100%|██████████| 1000/1000 [01:32<00:00, 10.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 52 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 53 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 53: 100%|██████████| 1000/1000 [01:13<00:00, 13.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 53 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 54 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 54: 100%|██████████| 1000/1000 [01:07<00:00, 14.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 54 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 55 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 55: 100%|██████████| 1000/1000 [01:10<00:00, 14.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 55 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 56 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 56: 100%|██████████| 1000/1000 [01:08<00:00, 14.60it/s]\n",
            "پردازش چانک 57: 100%|██████████| 1000/1000 [01:16<00:00, 13.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 57 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 58 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 58: 100%|██████████| 1000/1000 [01:07<00:00, 14.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 58 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 59 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 59: 100%|██████████| 1000/1000 [01:15<00:00, 13.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 59 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 60 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 60: 100%|██████████| 1000/1000 [01:13<00:00, 13.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 60 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 61 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 61: 100%|██████████| 1000/1000 [01:12<00:00, 13.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 61 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 62 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 62: 100%|██████████| 1000/1000 [01:15<00:00, 13.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 62 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 63 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 63: 100%|██████████| 1000/1000 [01:12<00:00, 13.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 63 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 64 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 64: 100%|██████████| 1000/1000 [01:07<00:00, 14.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 64 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 65 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 65: 100%|██████████| 1000/1000 [01:43<00:00,  9.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 65 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 66 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 66: 100%|██████████| 1000/1000 [01:10<00:00, 14.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 66 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 67 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 67: 100%|██████████| 1000/1000 [01:16<00:00, 13.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 67 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 68 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 68: 100%|██████████| 1000/1000 [01:07<00:00, 14.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 68 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 69 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 69: 100%|██████████| 1000/1000 [01:19<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 69 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 70 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 70: 100%|██████████| 1000/1000 [01:13<00:00, 13.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 70 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 71 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 71: 100%|██████████| 1000/1000 [01:10<00:00, 14.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 71 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 72 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 72: 100%|██████████| 1000/1000 [01:09<00:00, 14.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 72 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 73 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 73: 100%|██████████| 1000/1000 [01:07<00:00, 14.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 73 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 74 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 74: 100%|██████████| 1000/1000 [01:16<00:00, 13.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 74 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 75 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 75: 100%|██████████| 1000/1000 [01:32<00:00, 10.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 75 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 76 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 76: 100%|██████████| 1000/1000 [01:06<00:00, 15.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 76 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 77 با 1000 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 77: 100%|██████████| 1000/1000 [01:19<00:00, 12.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 77 با 1000 رکورد پردازش و به فایل CSV اضافه شد\n",
            "پردازش چانک 78 با 224 رکورد...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "پردازش چانک 78: 100%|██████████| 224/224 [00:18<00:00, 12.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ چانک 78 با 224 رکورد پردازش و به فایل CSV اضافه شد\n",
            "\n",
            "پردازش 77224 رکورد در 78 چانک به پایان رسید\n",
            "فایل CSV در /content/drive/MyDrive/Doukt/Goftino/NLP/colab/embedd/embeddings.csv ذخیره شد\n",
            "\n",
            "در حال تبدیل فایل CSV به Parquet...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "تبدیل به Parquet: 14it [16:06, 107.91s/it]"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np # type: ignore\n",
        "import time\n",
        "import os\n",
        "import concurrent.futures\n",
        "from tqdm import tqdm # type: ignore\n",
        "from openai import OpenAI # type: ignore\n",
        "\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "input_csv = \"/content/drive/MyDrive/Doukt/Goftino/NLP/colab/embedd/preproces.csv\"\n",
        "output_csv = \"/content/drive/MyDrive/Doukt/Goftino/NLP/colab/embedd/embeddings.csv\"\n",
        "output_parquet = \"/content/drive/MyDrive/Doukt/Goftino/NLP/colab/embedd/embeddings.parquet\"\n",
        "\n",
        "# Set chunk size for better performance\n",
        "chunksize = 1000\n",
        "first_chunk = True\n",
        "chunk_counter = 0\n",
        "total_processed = 0\n",
        "\n",
        "# Number of concurrent requests\n",
        "max_workers = 5\n",
        "\n",
        "# Remove output files if they already exist\n",
        "if os.path.exists(output_csv):\n",
        "    os.remove(output_csv)\n",
        "\n",
        "print(f\"Starting to process file {input_csv} with chunk size {chunksize} and {max_workers} concurrent requests...\")\n",
        "\n",
        "def get_embedding(text_data, max_retries=3, base_delay=1):\n",
        "    text, idx, original_idx = text_data\n",
        "    retries = 0\n",
        "\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            if pd.isna(text) or text.strip() == \"\":\n",
        "                return None, idx, original_idx\n",
        "\n",
        "            response = client.embeddings.create(\n",
        "                model=\"text-embedding-3-large\",\n",
        "                input=text\n",
        "            )\n",
        "\n",
        "            return response.data[0].embedding, idx, original_idx\n",
        "\n",
        "        except Exception as e:\n",
        "            retries += 1\n",
        "            error_msg = str(e).lower()\n",
        "\n",
        "            if \"rate_limit\" in error_msg:\n",
        "                delay = 30\n",
        "            else:\n",
        "                delay = base_delay * (2 ** (retries - 1))\n",
        "\n",
        "            if retries < max_retries:\n",
        "                print(f\"Error at index {original_idx} (attempt {retries} of {max_retries}): {e}\")\n",
        "                print(f\"Retrying after {delay} seconds...\")\n",
        "                time.sleep(delay)\n",
        "            else:\n",
        "                print(f\"Final error at index {original_idx} after {max_retries} attempts: {e}\")\n",
        "                return None, idx, original_idx\n",
        "\n",
        "    return None, idx, original_idx\n",
        "\n",
        "# Keep track of the total number of rows processed across all chunks\n",
        "base_index = 0\n",
        "\n",
        "for chunk in pd.read_csv(input_csv, chunksize=chunksize):\n",
        "    chunk_counter += 1\n",
        "    if \"preprocessed\" not in chunk.columns:\n",
        "        print(\"'preprocessed' column not found.\")\n",
        "        exit(1)\n",
        "\n",
        "    # Prepare data for parallel processing with original index\n",
        "    # For each row in the chunk, store: (preprocessed_text, position_in_chunk, original_position_in_csv)\n",
        "    texts_with_indices = []\n",
        "    for i, row in chunk.iterrows():\n",
        "        # Calculate original index in the whole CSV\n",
        "        original_idx = base_index + (i - chunk.index[0])\n",
        "        texts_with_indices.append((row[\"preprocessed\"], i, original_idx))\n",
        "\n",
        "    results = [None] * len(texts_with_indices)\n",
        "    original_indices_for_results = [None] * len(texts_with_indices)\n",
        "\n",
        "    print(f\"Processing chunk {chunk_counter} with {len(texts_with_indices)} records...\")\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        future_to_idx = {executor.submit(get_embedding, item): i for i, item in enumerate(texts_with_indices)}\n",
        "\n",
        "        for future in tqdm(concurrent.futures.as_completed(future_to_idx), total=len(texts_with_indices), desc=f\"Processing chunk {chunk_counter}\"):\n",
        "            idx = future_to_idx[future]\n",
        "            try:\n",
        "                embedding, _, original_idx = future.result()\n",
        "                if embedding is not None:\n",
        "                    results[idx] = embedding\n",
        "                    original_indices_for_results[idx] = original_idx\n",
        "            except Exception as e:\n",
        "                print(f\"Error while processing: {e}\")\n",
        "\n",
        "    # Remove None results while keeping original indices\n",
        "    valid_results = [(emb, idx) for emb, idx in zip(results, original_indices_for_results) if emb is not None]\n",
        "    if valid_results:\n",
        "        embeddings, indices = zip(*valid_results)\n",
        "\n",
        "        # Convert list of embeddings to DataFrame with numeric columns\n",
        "        arr = np.array(embeddings, dtype=np.float32)\n",
        "        df_emb = pd.DataFrame(arr, columns=[f\"dim_{i}\" for i in range(arr.shape[1])])\n",
        "\n",
        "        # Add original index column\n",
        "        df_emb.insert(0, 'original_index', indices)\n",
        "\n",
        "        # Save to CSV file (append mode)\n",
        "        if first_chunk:\n",
        "            df_emb.to_csv(output_csv, index=False, mode='w')\n",
        "            first_chunk = False\n",
        "        else:\n",
        "            df_emb.to_csv(output_csv, index=False, mode='a', header=False)\n",
        "\n",
        "        total_processed += len(embeddings)\n",
        "        print(f\"✅ Chunk {chunk_counter} with {len(embeddings)} records processed and appended to CSV\")\n",
        "\n",
        "        # Free memory\n",
        "        del arr, df_emb, embeddings, indices, valid_results\n",
        "\n",
        "    # Update the base_index for the next chunk\n",
        "    # We add the length of the current chunk to our running total\n",
        "    base_index += len(chunk)\n",
        "\n",
        "print(f\"\\nProcessing of {total_processed} records in {chunk_counter} chunks completed\")\n",
        "print(f\"CSV file saved at {output_csv}\")\n",
        "\n",
        "# Convert CSV file to Parquet\n",
        "print(\"\\nConverting CSV to Parquet...\")\n",
        "\n",
        "# Read CSV in small chunks and convert to Parquet\n",
        "csv_chunksize = 5000\n",
        "first_parquet_chunk = True\n",
        "\n",
        "for csv_chunk in tqdm(pd.read_csv(output_csv, chunksize=csv_chunksize), desc=\"Converting to Parquet\"):\n",
        "    if first_parquet_chunk:\n",
        "        csv_chunk.to_parquet(output_parquet, compression=\"snappy\", index=False)\n",
        "        first_parquet_chunk = False\n",
        "    else:\n",
        "        # For simplicity and reliability, we'll use the append method with a temporary file\n",
        "        temp_parquet = output_parquet + \".temp\"\n",
        "\n",
        "        # Read the existing parquet\n",
        "        existing_df = pd.read_parquet(output_parquet)\n",
        "\n",
        "        # Combine with new chunk\n",
        "        combined_df = pd.concat([existing_df, csv_chunk], ignore_index=True)\n",
        "\n",
        "        # Save to temp file\n",
        "        combined_df.to_parquet(temp_parquet, compression=\"snappy\", index=False)\n",
        "\n",
        "        # Replace original with temp\n",
        "        os.replace(temp_parquet, output_parquet)\n",
        "\n",
        "        # Clean up\n",
        "        del existing_df, combined_df\n",
        "\n",
        "print(f\"✅ Successfully converted to Parquet. Final file saved at {output_parquet}\")\n",
        "print(f\"\\n✅ All done! {total_processed} records processed. Both CSV and Parquet files saved:\")\n",
        "print(f\"- CSV file: {output_csv}\")\n",
        "print(f\"- Parquet file: {output_parquet}\")\n"
      ]
    }
  ]
}